{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from helper import generate_data, shuffleArraysInUnison\n",
    "from cvxopt import matrix, solvers\n",
    "from itertools import product\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsetData(images, labels, subset, label_dict):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in xrange(len(images)):\n",
    "        label = np.argmax(labels[i])\n",
    "        if label in subset:\n",
    "            label = label_dict[label]\n",
    "            X.append(images[i])\n",
    "            Y.append(label)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick data that hopefully isn't that seperable, subset it so we're doing linear classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosenLabels = set([3,8])\n",
    "label_dict = {3: -1, 8: 1}\n",
    "X_train, Y_train = subsetData(mnist.train.images, \n",
    "                              mnist.train.labels,\n",
    "                              chosenLabels, \n",
    "                              label_dict)\n",
    "\n",
    "X_test, Y_test = subsetData(mnist.test.images, \n",
    "                            mnist.test.labels,\n",
    "                            chosenLabels, \n",
    "                            label_dict)\n",
    "\n",
    "X_train, Y_train, _ = shuffleArraysInUnison(X_train, Y_train)\n",
    "X_test, Y_test, _ = shuffleArraysInUnison(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a couple of linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearSVC(C=5), \n",
    "          LinearSVC(loss='hinge', C=.1), \n",
    "          LinearSVC(loss='hinge', C=.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 784)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, Accuracy on Test Set\n",
      "0 0.941532258065\n",
      "\n",
      "Model, Accuracy on Test Set\n",
      "1 0.959677419355\n",
      "\n",
      "Model, Accuracy on Test Set\n",
      "2 0.96875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(models):\n",
    "    lb, ub = i * 1000, (i + 1) * 1000\n",
    "    model.fit(X_train[lb: ub], Y_train[lb: ub])\n",
    "    print \"Model, Accuracy on Test Set\"\n",
    "    print i, model.score(X_test, Y_test)\n",
    "    print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def subsetCorrect(num_pts, X, Y, models):\n",
    "#     num_selected = 0\n",
    "#     num_models = len(models)\n",
    "#     resX = []\n",
    "#     resY = []\n",
    "#     for i in xrange(len(X)):\n",
    "#         allCorrect = sum([model.score(X[i:i+1], Y[i:i+1]) for model in models]) == num_models\n",
    "#         if allCorrect:\n",
    "#             resX.append(X[i])\n",
    "#             resY.append(Y[i])\n",
    "#             num_selected += 1\n",
    "#         if num_selected == num_pts:\n",
    "#             break\n",
    "#     if num_selected < num_pts:\n",
    "#         print \"Not enough points were correctly predicted by all models\"\n",
    "#     return np.array(resX), np.array(resY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalX, evalY = generate_data(300, X_test, Y_test, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select points that are correctly classified by all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.score(evalX, evalY) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistsToPlanes(models, X, Y):\n",
    "    dists = []\n",
    "    min_max = []\n",
    "    num_models = len(models)\n",
    "    num_points = len(X)\n",
    "    norms = [np.linalg.norm(model.coef_) for model in models]\n",
    "    for i in xrange(num_points):\n",
    "        d = []\n",
    "        for j in xrange(num_models):    \n",
    "            # the reshaping happens so sklearn doesn't complain\n",
    "            isCorrect = models[j].predict(X[i].reshape(1,-1))[0] == Y[i] \n",
    "            if isCorrect:\n",
    "                d.append(abs((np.dot(models[j].coef_, X[i]) + models[j].intercept_)) / norms[j])\n",
    "            else:\n",
    "                d.append(np.nan)\n",
    "        min_max.append((min(d), max(d)))\n",
    "        dists.append(d)\n",
    "    return np.array(dists).reshape(num_points, num_models), np.array(min_max).reshape(num_points, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dists, min_max = computeDistsToPlanes(models, evalX, evalY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.66828733  0.95834482  1.43564241]\n"
     ]
    }
   ],
   "source": [
    "print np.mean(dists, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluates the loss function in a particular region on $n$ dimensional space as determined by the signs list (what side of each hyperplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryRegionBinary(models, signs, x, delta=1e-11):\n",
    "    P = matrix(np.identity(x.shape[0]))\n",
    "    q = matrix(np.zeros(x.shape[0]))\n",
    "    h = []\n",
    "    G = []\n",
    "    num_models = len(models)\n",
    "    for i in xrange(num_models):\n",
    "        coef, intercept = models[i].coef_, models[i].intercept_\n",
    "        ineq_val  = -1.0 * delta + signs[i] * (np.dot(coef, x) + intercept) \n",
    "        h.append(ineq_val[0])\n",
    "        G.append(-1.0 * signs[i] * coef.reshape(-1,))   \n",
    "    h = matrix(h)\n",
    "    G = matrix(np.array(G))\n",
    "    solvers.options['show_progress'] = False\n",
    "    sol = solvers.qp(P, q, G, h)\n",
    "    if sol['status'] == 'optimal':\n",
    "        v = np.array(sol['x']).reshape(-1,)\n",
    "        perturbed_x = np.array(x + v).reshape(1, -1)\n",
    "        is_desired_sign = [models[i].predict(perturbed_x)[0] == signs[i] for i in xrange(num_models)]\n",
    "        if sum(is_desired_sign) == num_models:\n",
    "            return v\n",
    "        else:\n",
    "            return tryRegionBinary(models, signs, x, delta * 1.5)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 0.72845398  0.75716875  1.23775079]\n"
     ]
    }
   ],
   "source": [
    "test = 14\n",
    "print evalY[test]\n",
    "print dists[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2663893147\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "# the labels that you specify for the region should match the labels predicted by the models\n",
    "sol = tryRegionBinary(models, [-1, -1, -1], evalX[test])\n",
    "print np.linalg.norm(sol)\n",
    "for model in models:\n",
    "    print model.predict(evalX[test].reshape(1,-1) + sol)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tries all $2^n$ possible regions of space to find the maximum value of the function while respecting the constraint that the noise vector $||v|| < \\alpha $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findExampleBinary(weights, models, x, y, alpha):\n",
    "    candidates = []\n",
    "    \n",
    "    # we should only take into consideration models that we could feasibly trickm\n",
    "    dists, _ = computeDistsToPlanes(models, x.reshape(1, -1), y.reshape(1, -1))\n",
    "    feasible_models = [models[i] for i in xrange(len(models)) if dists[0][i] < alpha]\n",
    "    \n",
    "    num_models = len(feasible_models)\n",
    "    # can't trick anything\n",
    "    if num_models == 0:\n",
    "        return np.zeros(x.shape)\n",
    "    \n",
    "    rel_weights = np.array([weights[i] for i in xrange(len(models)) if dists[0][i] < alpha])\n",
    "    \n",
    "    signs_values = []\n",
    "    for signs in product([-1.0, 1.0], repeat=num_models): # iterate over all possible regions\n",
    "        is_misclassified = np.equal(-1.0 * y * np.ones(num_models), signs) # y = -1, or 1\n",
    "        value = np.dot(is_misclassified, rel_weights)\n",
    "        signs_values.append((signs, value))\n",
    "    \n",
    "    values = sorted(set([value for signs, value in signs_values]), reverse=True)\n",
    "    for value in values:\n",
    "        feasible_candidates = []\n",
    "        for signs in [sign for sign, val in signs_values if val == value]:\n",
    "            v = tryRegionBinary(feasible_models, signs, x)\n",
    "            if v is not None:\n",
    "                norm = np.linalg.norm(v)\n",
    "                if norm <= alpha:\n",
    "                    feasible_candidates.append((v, norm))\n",
    "        # amongst those with the max value, return the one with the minimum norm\n",
    "        if feasible_candidates:\n",
    "            # break out of the loop since we have already found the optimal answer\n",
    "            return min(feasible_candidates, key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finds adversarial noise vectors for each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = findExampleBinary(np.array([0.2, 0.2, 0.6]), models, X_test[0], Y_test[0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72178468127\n",
      "-1\n",
      "-1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print np.linalg.norm(v)\n",
    "for model in models:\n",
    "    print model.predict(X_test[0].reshape(1,-1) + v)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Oracle(weights, models, X, Y, alpha, findExample):\n",
    "    return np.array([findExample(weights, models, x, y, alpha) for x, y in zip(X,Y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets the costs of each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateCosts(models, V, X, Y):\n",
    "    return np.array([1 - model.score(X + V, Y) for model in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runMWU(models, T, X, Y, alpha, findExample, epsilon=None):\n",
    "    \n",
    "    num_models = len(models)\n",
    "    \n",
    "    if epsilon is None:\n",
    "        delta = np.sqrt(4 * np.log(num_models) / float(T))\n",
    "        epsilon = delta / 2.0\n",
    "    else:\n",
    "        delta = 2.0 * epsilon\n",
    "\n",
    "    \n",
    "    print \"Running MWU for {} Iterations with Epsilon {}\\n\".format(T, epsilon)\n",
    "\n",
    "    print \"Guaranteed to be within {} of the minimax value \\n\".format(delta)\n",
    "    \n",
    "    loss_history = []\n",
    "    costs = []\n",
    "    max_acc_history = []\n",
    "    v = []\n",
    "    w = []\n",
    "    \n",
    "    w.append(np.ones(num_models) / num_models)\n",
    "\n",
    "    for t in xrange(T):\n",
    "        print \"Iteration \", t\n",
    "        print \n",
    "        start_time = time.time()\n",
    "        \n",
    "        v_t = Oracle(w[t], models, X, Y, alpha, findExample)\n",
    "        v.append(v_t)\n",
    "        \n",
    "        cost_t = evaluateCosts(models, v_t, X, Y)\n",
    "        costs.append(cost_t)\n",
    "        \n",
    "        print \"Shape of costs matrix\", np.array(costs).shape\n",
    "        avg_acc = np.mean((1 - np.array(costs)), axis=0)  \n",
    "        max_acc = max(avg_acc)\n",
    "        max_acc_history.append(max_acc)\n",
    "        \n",
    "        loss = np.dot(w[t], cost_t)\n",
    "    \n",
    "        print \"Weights, \", w[t], sum(w[t])\n",
    "        print \"Maximum (Average) Accuracy of Classifier \", max_acc\n",
    "        print \"Cost (Before Noise), \", np.array([1 - model.score(X, Y) for model in models])\n",
    "        print \"Cost (After Noise), \", cost_t\n",
    "        print \"Loss, \", loss\n",
    "        \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        new_w = np.copy(w[t])\n",
    "        \n",
    "        # penalize experts\n",
    "        for i in xrange(num_models):\n",
    "            new_w[i] *= (1.0 - epsilon) ** cost_t[i]\n",
    "        \n",
    "        # renormalize weights\n",
    "        w_sum = new_w.sum()\n",
    "        for i in xrange(num_models - 1):\n",
    "            new_w[i] = new_w[i] / w_sum\n",
    "        new_w[-1] = 1.0 - new_w[:-1].sum()\n",
    "        \n",
    "        w.append(new_w)\n",
    "        \n",
    "        print\n",
    "        print \"time spent \", time.time() - start_time\n",
    "        print\n",
    "        \n",
    "    return w, v, loss_history, max_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists, minmax = computeDistsToPlanes(models, evalX, evalY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that these are all points that are correctly predicted by all the models\n",
    "[model.score(evalX, evalY) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66828733,  0.95834482,  1.43564241])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dists, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MWU for 100 Iterations with Epsilon 0.104814707397\n",
      "\n",
      "Guaranteed to be within 0.209629414794 of the minimax value \n",
      "\n",
      "Iteration  0\n",
      "\n",
      "Shape of costs matrix (1, 3)\n",
      "Weights,  [ 0.33333333  0.33333333  0.33333333] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.77\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.78333333  0.45        0.23      ]\n",
      "Loss,  0.487777777778\n",
      "\n",
      "time spent  117.765130043\n",
      "\n",
      "Iteration  1\n",
      "\n",
      "Shape of costs matrix (2, 3)\n",
      "Weights,  [ 0.32249938  0.33462463  0.34287598] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.765\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.482715437281\n",
      "\n",
      "time spent  118.608344078\n",
      "\n",
      "Iteration  2\n",
      "\n",
      "Shape of costs matrix (3, 3)\n",
      "Weights,  [ 0.31347868  0.33439424  0.35212708] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.763333333333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.478178323894\n",
      "\n",
      "time spent  116.379616022\n",
      "\n",
      "Iteration  3\n",
      "\n",
      "Shape of costs matrix (4, 3)\n",
      "Weights,  [ 0.30455738  0.33399632  0.3614463 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.7625\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.473649257701\n",
      "\n",
      "time spent  116.57549715\n",
      "\n",
      "Iteration  4\n",
      "\n",
      "Shape of costs matrix (5, 3)\n",
      "Weights,  [ 0.29574181  0.33343182  0.37082638] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.762\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.469131612109\n",
      "\n",
      "time spent  116.236505985\n",
      "\n",
      "Iteration  5\n",
      "\n",
      "Shape of costs matrix (6, 3)\n",
      "Weights,  [ 0.28703801  0.33270207  0.38025992] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.761666666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.464628723135\n",
      "\n",
      "time spent  117.177347898\n",
      "\n",
      "Iteration  6\n",
      "\n",
      "Shape of costs matrix (7, 3)\n",
      "Weights,  [ 0.27845178  0.33180876  0.38973946] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.761428571429\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.460143878852\n",
      "\n",
      "time spent  116.049807072\n",
      "\n",
      "Iteration  7\n",
      "\n",
      "Shape of costs matrix (8, 3)\n",
      "Weights,  [ 0.2699886   0.33075395  0.39925746] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.76125\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.455680309169\n",
      "\n",
      "time spent  114.317369938\n",
      "\n",
      "Iteration  8\n",
      "\n",
      "Shape of costs matrix (9, 3)\n",
      "Weights,  [ 0.26165364  0.32954001  0.40880635] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.761111111111\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.451241176015\n",
      "\n",
      "time spent  114.605862141\n",
      "\n",
      "Iteration  9\n",
      "\n",
      "Shape of costs matrix (10, 3)\n",
      "Weights,  [ 0.25345176  0.32816968  0.41837855] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.761\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.446829563994\n",
      "\n",
      "time spent  114.457946062\n",
      "\n",
      "Iteration  10\n",
      "\n",
      "Shape of costs matrix (11, 3)\n",
      "Weights,  [ 0.2453875  0.326646   0.4279665] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760909090909\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.442448471562\n",
      "\n",
      "time spent  114.308690071\n",
      "\n",
      "Iteration  11\n",
      "\n",
      "Shape of costs matrix (12, 3)\n",
      "Weights,  [ 0.23746504  0.3249723   0.43756266] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760833333333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.438100802782\n",
      "\n",
      "time spent  114.646234989\n",
      "\n",
      "Iteration  12\n",
      "\n",
      "Shape of costs matrix (13, 3)\n",
      "Weights,  [ 0.22968821  0.32315222  0.44715957] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760769230769\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.433789359696\n",
      "\n",
      "time spent  114.629590988\n",
      "\n",
      "Iteration  13\n",
      "\n",
      "Shape of costs matrix (14, 3)\n",
      "Weights,  [ 0.22206051  0.32118965  0.45674984] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760714285714\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.429516835369\n",
      "\n",
      "time spent  114.569569826\n",
      "\n",
      "Iteration  14\n",
      "\n",
      "Shape of costs matrix (15, 3)\n",
      "Weights,  [ 0.21458507  0.31908874  0.46632619] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760666666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.425285807609\n",
      "\n",
      "time spent  114.249988079\n",
      "\n",
      "Iteration  15\n",
      "\n",
      "Shape of costs matrix (16, 3)\n",
      "Weights,  [ 0.20726466  0.31685386  0.47588148] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760625\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.421098733413\n",
      "\n",
      "time spent  114.26714015\n",
      "\n",
      "Iteration  16\n",
      "\n",
      "Shape of costs matrix (17, 3)\n",
      "Weights,  [ 0.2001017   0.31448959  0.48540871] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760588235294\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.416957944138\n",
      "\n",
      "time spent  114.666177988\n",
      "\n",
      "Iteration  17\n",
      "\n",
      "Shape of costs matrix (18, 3)\n",
      "Weights,  [ 0.19309825  0.31200072  0.49490103] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760555555556\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73666667  0.48666667  0.24      ]\n",
      "Loss,  0.412865641415\n",
      "\n",
      "time spent  114.193598986\n",
      "\n",
      "Iteration  18\n",
      "\n",
      "Shape of costs matrix (19, 3)\n",
      "Weights,  [ 0.18625602  0.30939219  0.5043518 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760350877193\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.408852905791\n",
      "\n",
      "time spent  114.614732981\n",
      "\n",
      "Iteration  19\n",
      "\n",
      "Shape of costs matrix (20, 3)\n",
      "Weights,  [ 0.17964447  0.30678537  0.51357016] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.760166666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.404987613581\n",
      "\n",
      "time spent  114.250669003\n",
      "\n",
      "Iteration  20\n",
      "\n",
      "Shape of costs matrix (21, 3)\n",
      "Weights,  [ 0.17319398  0.30407125  0.52273477] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.76\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.401175485417\n",
      "\n",
      "time spent  114.135146141\n",
      "\n",
      "Iteration  21\n",
      "\n",
      "Shape of costs matrix (22, 3)\n",
      "Weights,  [ 0.16690515  0.30125486  0.53183998] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759848484848\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.397418024816\n",
      "\n",
      "time spent  114.727239132\n",
      "\n",
      "Iteration  22\n",
      "\n",
      "Shape of costs matrix (23, 3)\n",
      "Weights,  [ 0.16077826  0.29834134  0.5408804 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759710144928\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.393716603963\n",
      "\n",
      "time spent  114.184477091\n",
      "\n",
      "Iteration  23\n",
      "\n",
      "Shape of costs matrix (24, 3)\n",
      "Weights,  [ 0.15481332  0.29533586  0.54985083] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759583333333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.390072464236\n",
      "\n",
      "time spent  114.218764067\n",
      "\n",
      "Iteration  24\n",
      "\n",
      "Shape of costs matrix (25, 3)\n",
      "Weights,  [ 0.14901002  0.29224365  0.55874633] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759466666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.386486717288\n",
      "\n",
      "time spent  114.396003962\n",
      "\n",
      "Iteration  25\n",
      "\n",
      "Shape of costs matrix (26, 3)\n",
      "Weights,  [ 0.14336779  0.28906998  0.56756223] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759358974359\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.382960346659\n",
      "\n",
      "time spent  114.260091066\n",
      "\n",
      "Iteration  26\n",
      "\n",
      "Shape of costs matrix (27, 3)\n",
      "Weights,  [ 0.13788582  0.2858201   0.57629408] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759259259259\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.379494209877\n",
      "\n",
      "time spent  114.532721043\n",
      "\n",
      "Iteration  27\n",
      "\n",
      "Shape of costs matrix (28, 3)\n",
      "Weights,  [ 0.13256303  0.28249927  0.5849377 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759166666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.37608904101\n",
      "\n",
      "time spent  114.214191914\n",
      "\n",
      "Iteration  28\n",
      "\n",
      "Shape of costs matrix (29, 3)\n",
      "Weights,  [ 0.1273981   0.27911272  0.59348918] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75908045977\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.372745453635\n",
      "\n",
      "time spent  114.956519842\n",
      "\n",
      "Iteration  29\n",
      "\n",
      "Shape of costs matrix (30, 3)\n",
      "Weights,  [ 0.12238951  0.27566564  0.60194486] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.759\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.369463944169\n",
      "\n",
      "time spent  114.42688179\n",
      "\n",
      "Iteration  30\n",
      "\n",
      "Shape of costs matrix (31, 3)\n",
      "Weights,  [ 0.11753552  0.27216316  0.61030132] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758924731183\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.366244895537\n",
      "\n",
      "time spent  114.208362103\n",
      "\n",
      "Iteration  31\n",
      "\n",
      "Shape of costs matrix (32, 3)\n",
      "Weights,  [ 0.11283421  0.26861036  0.61855543] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758854166667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.363088581126\n",
      "\n",
      "time spent  114.119643927\n",
      "\n",
      "Iteration  32\n",
      "\n",
      "Shape of costs matrix (33, 3)\n",
      "Weights,  [ 0.10828347  0.26501223  0.6267043 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758787878788\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.359995168991\n",
      "\n",
      "time spent  114.334841967\n",
      "\n",
      "Iteration  33\n",
      "\n",
      "Shape of costs matrix (34, 3)\n",
      "Weights,  [ 0.10388105  0.26137367  0.63474529] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758725490196\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.356964726259\n",
      "\n",
      "time spent  114.179190159\n",
      "\n",
      "Iteration  34\n",
      "\n",
      "Shape of costs matrix (35, 3)\n",
      "Weights,  [ 0.09962452  0.25769948  0.642676  ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758666666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.353997223714\n",
      "\n",
      "time spent  114.40346384\n",
      "\n",
      "Iteration  35\n",
      "\n",
      "Shape of costs matrix (36, 3)\n",
      "Weights,  [ 0.09551135  0.25399435  0.6504943 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758611111111\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.351092540511\n",
      "\n",
      "time spent  114.16264987\n",
      "\n",
      "Iteration  36\n",
      "\n",
      "Shape of costs matrix (37, 3)\n",
      "Weights,  [ 0.09153888  0.25026286  0.65819827] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758558558559\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.34825046898\n",
      "\n",
      "time spent  114.344599962\n",
      "\n",
      "Iteration  37\n",
      "\n",
      "Shape of costs matrix (38, 3)\n",
      "Weights,  [ 0.08770432  0.24650945  0.66578623] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75850877193\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.345470719505\n",
      "\n",
      "time spent  114.394296885\n",
      "\n",
      "Iteration  38\n",
      "\n",
      "Shape of costs matrix (39, 3)\n",
      "Weights,  [ 0.08400483  0.24273845  0.67325673] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758461538462\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.342752925425\n",
      "\n",
      "time spent  114.192574024\n",
      "\n",
      "Iteration  39\n",
      "\n",
      "Shape of costs matrix (40, 3)\n",
      "Weights,  [ 0.08043744  0.23895403  0.68060853] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758416666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.340096647943\n",
      "\n",
      "time spent  114.318872929\n",
      "\n",
      "Iteration  40\n",
      "\n",
      "Shape of costs matrix (41, 3)\n",
      "Weights,  [ 0.07699917  0.23516024  0.6878406 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75837398374\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.33750138101\n",
      "\n",
      "time spent  114.222591877\n",
      "\n",
      "Iteration  41\n",
      "\n",
      "Shape of costs matrix (42, 3)\n",
      "Weights,  [ 0.07368693  0.23136096  0.69495212] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758333333333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.334966556158\n",
      "\n",
      "time spent  114.260317802\n",
      "\n",
      "Iteration  42\n",
      "\n",
      "Shape of costs matrix (43, 3)\n",
      "Weights,  [ 0.07049761  0.22755994  0.70194245] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758294573643\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.332491547262\n",
      "\n",
      "time spent  114.320451975\n",
      "\n",
      "Iteration  43\n",
      "\n",
      "Shape of costs matrix (44, 3)\n",
      "Weights,  [ 0.06742808  0.22376077  0.70881116] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758257575758\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.330075675215\n",
      "\n",
      "time spent  114.21769309\n",
      "\n",
      "Iteration  44\n",
      "\n",
      "Shape of costs matrix (45, 3)\n",
      "Weights,  [ 0.06447515  0.21996689  0.71555796] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758222222222\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.327718212489\n",
      "\n",
      "time spent  114.270061016\n",
      "\n",
      "Iteration  45\n",
      "\n",
      "Shape of costs matrix (46, 3)\n",
      "Weights,  [ 0.06163566  0.2161816   0.72218275] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758188405797\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.325418387574\n",
      "\n",
      "time spent  114.432456017\n",
      "\n",
      "Iteration  46\n",
      "\n",
      "Shape of costs matrix (47, 3)\n",
      "Weights,  [ 0.05890639  0.21240801  0.72868559] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758156028369\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.323175389278\n",
      "\n",
      "time spent  114.181029081\n",
      "\n",
      "Iteration  47\n",
      "\n",
      "Shape of costs matrix (48, 3)\n",
      "Weights,  [ 0.05628418  0.20864912  0.7350667 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758125\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.320988370881\n",
      "\n",
      "time spent  114.600193977\n",
      "\n",
      "Iteration  48\n",
      "\n",
      "Shape of costs matrix (49, 3)\n",
      "Weights,  [ 0.05376584  0.20490776  0.74132641] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758095238095\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.318856454131\n",
      "\n",
      "time spent  114.119060993\n",
      "\n",
      "Iteration  49\n",
      "\n",
      "Shape of costs matrix (50, 3)\n",
      "Weights,  [ 0.0513482   0.20118658  0.74746521] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758066666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.31677873307\n",
      "\n",
      "time spent  114.563227892\n",
      "\n",
      "Iteration  50\n",
      "\n",
      "Shape of costs matrix (51, 3)\n",
      "Weights,  [ 0.04902815  0.19748813  0.75348372] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758039215686\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.314754277694\n",
      "\n",
      "time spent  114.447499037\n",
      "\n",
      "Iteration  51\n",
      "\n",
      "Shape of costs matrix (52, 3)\n",
      "Weights,  [ 0.04680256  0.19381479  0.75938265] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.758012820513\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.312782137441\n",
      "\n",
      "time spent  114.151806116\n",
      "\n",
      "Iteration  52\n",
      "\n",
      "Shape of costs matrix (53, 3)\n",
      "Weights,  [ 0.04466838  0.19016878  0.76516285] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757987421384\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.31086134449\n",
      "\n",
      "time spent  114.193881989\n",
      "\n",
      "Iteration  53\n",
      "\n",
      "Shape of costs matrix (54, 3)\n",
      "Weights,  [ 0.04262256  0.1865522   0.77082524] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757962962963\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.308990916899\n",
      "\n",
      "time spent  114.651432037\n",
      "\n",
      "Iteration  54\n",
      "\n",
      "Shape of costs matrix (55, 3)\n",
      "Weights,  [ 0.04066214  0.18296701  0.77637086] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757939393939\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.307169861545\n",
      "\n",
      "time spent  114.274740219\n",
      "\n",
      "Iteration  55\n",
      "\n",
      "Shape of costs matrix (56, 3)\n",
      "Weights,  [ 0.03878416  0.17941501  0.78180082] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757916666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.305397176906\n",
      "\n",
      "time spent  114.740462065\n",
      "\n",
      "Iteration  56\n",
      "\n",
      "Shape of costs matrix (57, 3)\n",
      "Weights,  [ 0.03698576  0.17589791  0.78711633] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757894736842\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.303671855652\n",
      "\n",
      "time spent  114.192018032\n",
      "\n",
      "Iteration  57\n",
      "\n",
      "Shape of costs matrix (58, 3)\n",
      "Weights,  [ 0.0352641   0.17241726  0.79231863] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757873563218\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.301992887076\n",
      "\n",
      "time spent  114.186465979\n",
      "\n",
      "Iteration  58\n",
      "\n",
      "Shape of costs matrix (59, 3)\n",
      "Weights,  [ 0.03361642  0.16897449  0.79740908] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757853107345\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.300359259347\n",
      "\n",
      "time spent  114.360672951\n",
      "\n",
      "Iteration  59\n",
      "\n",
      "Shape of costs matrix (60, 3)\n",
      "Weights,  [ 0.03204001  0.16557093  0.80238906] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757833333333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.298769961608\n",
      "\n",
      "time spent  114.173809052\n",
      "\n",
      "Iteration  60\n",
      "\n",
      "Shape of costs matrix (61, 3)\n",
      "Weights,  [ 0.03053222  0.16220776  0.80726001] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75781420765\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.297223985906\n",
      "\n",
      "time spent  114.426260948\n",
      "\n",
      "Iteration  61\n",
      "\n",
      "Shape of costs matrix (62, 3)\n",
      "Weights,  [ 0.02909048  0.15888608  0.81202344] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757795698925\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.295720328979\n",
      "\n",
      "time spent  114.396854162\n",
      "\n",
      "Iteration  62\n",
      "\n",
      "Shape of costs matrix (63, 3)\n",
      "Weights,  [ 0.02771227  0.15560687  0.81668086] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757777777778\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.294257993882\n",
      "\n",
      "time spent  114.081130028\n",
      "\n",
      "Iteration  63\n",
      "\n",
      "Shape of costs matrix (64, 3)\n",
      "Weights,  [ 0.02639513  0.15237101  0.82123386] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757760416667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.292835991483\n",
      "\n",
      "time spent  114.428416967\n",
      "\n",
      "Iteration  64\n",
      "\n",
      "Shape of costs matrix (65, 3)\n",
      "Weights,  [ 0.0251367   0.14917927  0.82568403] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757743589744\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.291453341813\n",
      "\n",
      "time spent  114.223394156\n",
      "\n",
      "Iteration  65\n",
      "\n",
      "Shape of costs matrix (66, 3)\n",
      "Weights,  [ 0.02393465  0.14603235  0.830033  ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757727272727\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.290109075298\n",
      "\n",
      "time spent  114.627026796\n",
      "\n",
      "Iteration  66\n",
      "\n",
      "Shape of costs matrix (67, 3)\n",
      "Weights,  [ 0.02278674  0.14293083  0.83428243] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757711442786\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.288802233856\n",
      "\n",
      "time spent  114.561713934\n",
      "\n",
      "Iteration  67\n",
      "\n",
      "Shape of costs matrix (68, 3)\n",
      "Weights,  [ 0.02169078  0.13987523  0.83843399] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757696078431\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.287531871885\n",
      "\n",
      "time spent  114.244184971\n",
      "\n",
      "Iteration  68\n",
      "\n",
      "Shape of costs matrix (69, 3)\n",
      "Weights,  [ 0.02064468  0.13686596  0.84248936] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75768115942\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.286297057135\n",
      "\n",
      "time spent  114.487166882\n",
      "\n",
      "Iteration  69\n",
      "\n",
      "Shape of costs matrix (70, 3)\n",
      "Weights,  [ 0.01964638  0.13390339  0.84645023] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757666666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.285096871485\n",
      "\n",
      "time spent  114.46216917\n",
      "\n",
      "Iteration  70\n",
      "\n",
      "Shape of costs matrix (71, 3)\n",
      "Weights,  [ 0.0186939   0.13098778  0.85031832] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.75765258216\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.283930411611\n",
      "\n",
      "time spent  115.586815834\n",
      "\n",
      "Iteration  71\n",
      "\n",
      "Shape of costs matrix (72, 3)\n",
      "Weights,  [ 0.01778534  0.12811934  0.85409532] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757638888889\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.28279678957\n",
      "\n",
      "time spent  114.434494972\n",
      "\n",
      "Iteration  72\n",
      "\n",
      "Shape of costs matrix (73, 3)\n",
      "Weights,  [ 0.01691884  0.12529821  0.85778295] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757625570776\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.281695133297\n",
      "\n",
      "time spent  114.29096508\n",
      "\n",
      "Iteration  73\n",
      "\n",
      "Shape of costs matrix (74, 3)\n",
      "Weights,  [ 0.01609262  0.12252446  0.86138292] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757612612613\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.28062458702\n",
      "\n",
      "time spent  114.281520844\n",
      "\n",
      "Iteration  74\n",
      "\n",
      "Shape of costs matrix (75, 3)\n",
      "Weights,  [ 0.01530496  0.11979812  0.86489692] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.7576\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.279584311602\n",
      "\n",
      "time spent  114.742569208\n",
      "\n",
      "Iteration  75\n",
      "\n",
      "Shape of costs matrix (76, 3)\n",
      "Weights,  [ 0.0145542   0.11711915  0.86832666] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757587719298\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.278573484815\n",
      "\n",
      "time spent  114.292954922\n",
      "\n",
      "Iteration  76\n",
      "\n",
      "Shape of costs matrix (77, 3)\n",
      "Weights,  [ 0.01383874  0.11448745  0.87167382] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757575757576\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.277591301548\n",
      "\n",
      "time spent  114.398395061\n",
      "\n",
      "Iteration  77\n",
      "\n",
      "Shape of costs matrix (78, 3)\n",
      "Weights,  [ 0.01315704  0.11190289  0.87494008] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757564102564\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.276636973962\n",
      "\n",
      "time spent  114.151479006\n",
      "\n",
      "Iteration  78\n",
      "\n",
      "Shape of costs matrix (79, 3)\n",
      "Weights,  [ 0.01250762  0.10936528  0.87812711] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757552742616\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.275709731579\n",
      "\n",
      "time spent  114.144395113\n",
      "\n",
      "Iteration  79\n",
      "\n",
      "Shape of costs matrix (80, 3)\n",
      "Weights,  [ 0.01188904  0.1068744   0.88123656] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757541666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.274808821338\n",
      "\n",
      "time spent  114.380249023\n",
      "\n",
      "Iteration  80\n",
      "\n",
      "Shape of costs matrix (81, 3)\n",
      "Weights,  [ 0.01129996  0.10442998  0.88427006] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757530864198\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.273933507592\n",
      "\n",
      "time spent  114.353969097\n",
      "\n",
      "Iteration  81\n",
      "\n",
      "Shape of costs matrix (82, 3)\n",
      "Weights,  [ 0.01073903  0.10203173  0.88722924] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757520325203\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.27308307207\n",
      "\n",
      "time spent  114.73844409\n",
      "\n",
      "Iteration  82\n",
      "\n",
      "Shape of costs matrix (83, 3)\n",
      "Weights,  [ 0.010205   0.0996793  0.8901157] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757510040161\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.272256813802\n",
      "\n",
      "time spent  114.057782888\n",
      "\n",
      "Iteration  83\n",
      "\n",
      "Shape of costs matrix (84, 3)\n",
      "Weights,  [ 0.00969665  0.09737232  0.89293103] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.7575\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.271454049005\n",
      "\n",
      "time spent  114.18637991\n",
      "\n",
      "Iteration  84\n",
      "\n",
      "Shape of costs matrix (85, 3)\n",
      "Weights,  [ 0.00921282  0.0951104   0.89567678] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757490196078\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.270674110951\n",
      "\n",
      "time spent  114.358031034\n",
      "\n",
      "Iteration  85\n",
      "\n",
      "Shape of costs matrix (86, 3)\n",
      "Weights,  [ 0.00875238  0.09289312  0.8983545 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757480620155\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.269916349791\n",
      "\n",
      "time spent  114.300077915\n",
      "\n",
      "Iteration  86\n",
      "\n",
      "Shape of costs matrix (87, 3)\n",
      "Weights,  [ 0.00831427  0.09072003  0.9009657 ] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757471264368\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.269180132368\n",
      "\n",
      "time spent  114.218856096\n",
      "\n",
      "Iteration  87\n",
      "\n",
      "Shape of costs matrix (88, 3)\n",
      "Weights,  [ 0.00789745  0.08859065  0.90351189] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757462121212\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.268464842002\n",
      "\n",
      "time spent  114.425383091\n",
      "\n",
      "Iteration  88\n",
      "\n",
      "Shape of costs matrix (89, 3)\n",
      "Weights,  [ 0.00750095  0.0865045   0.90599455] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757453183521\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.267769878262\n",
      "\n",
      "time spent  114.483151913\n",
      "\n",
      "Iteration  89\n",
      "\n",
      "Shape of costs matrix (90, 3)\n",
      "Weights,  [ 0.00712381  0.08446107  0.90841512] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757444444444\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.267094656711\n",
      "\n",
      "time spent  114.527586937\n",
      "\n",
      "Iteration  90\n",
      "\n",
      "Shape of costs matrix (91, 3)\n",
      "Weights,  [ 0.00676513  0.08245983  0.91077503] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757435897436\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.266438608652\n",
      "\n",
      "time spent  114.208722115\n",
      "\n",
      "Iteration  91\n",
      "\n",
      "Shape of costs matrix (92, 3)\n",
      "Weights,  [ 0.00642406  0.08050025  0.91307569] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757427536232\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.265801180846\n",
      "\n",
      "time spent  114.377030134\n",
      "\n",
      "Iteration  92\n",
      "\n",
      "Shape of costs matrix (93, 3)\n",
      "Weights,  [ 0.00609975  0.07858177  0.91531848] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757419354839\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.265181835231\n",
      "\n",
      "time spent  114.351432085\n",
      "\n",
      "Iteration  93\n",
      "\n",
      "Shape of costs matrix (94, 3)\n",
      "Weights,  [ 0.00579143  0.07670382  0.91750476] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757411347518\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.264580048628\n",
      "\n",
      "time spent  114.42410183\n",
      "\n",
      "Iteration  94\n",
      "\n",
      "Shape of costs matrix (95, 3)\n",
      "Weights,  [ 0.00549833  0.07486583  0.91963584] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757403508772\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.263995312441\n",
      "\n",
      "time spent  114.158326864\n",
      "\n",
      "Iteration  95\n",
      "\n",
      "Shape of costs matrix (96, 3)\n",
      "Weights,  [ 0.00521973  0.07306722  0.92171305] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757395833333\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.26342713235\n",
      "\n",
      "time spent  114.484287024\n",
      "\n",
      "Iteration  96\n",
      "\n",
      "Shape of costs matrix (97, 3)\n",
      "Weights,  [ 0.00495493  0.0713074   0.92373766] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757388316151\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.262875028002\n",
      "\n",
      "time spent  114.235454082\n",
      "\n",
      "Iteration  97\n",
      "\n",
      "Shape of costs matrix (98, 3)\n",
      "Weights,  [ 0.00470329  0.06958578  0.92571093] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757380952381\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.2623385327\n",
      "\n",
      "time spent  114.405055046\n",
      "\n",
      "Iteration  98\n",
      "\n",
      "Shape of costs matrix (99, 3)\n",
      "Weights,  [ 0.00446417  0.06790174  0.92763409] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757373737374\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.261817193084\n",
      "\n",
      "time spent  114.136723995\n",
      "\n",
      "Iteration  99\n",
      "\n",
      "Shape of costs matrix (100, 3)\n",
      "Weights,  [ 0.00423696  0.06625468  0.92950835] 1.0\n",
      "Maximum (Average) Accuracy of Classifier  0.757366666667\n",
      "Cost (Before Noise),  [ 0.  0.  0.]\n",
      "Cost (After Noise),  [ 0.73333333  0.48333333  0.24333333]\n",
      "Loss,  0.26131056882\n",
      "\n",
      "time spent  114.369102001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = runMWU(models, 100, evalX, evalY, .95, findExampleBinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, v, loss_history, max_acc_history = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = \"binary_oracle2\"\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.mkdir(exp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w, v, loss_history, max_acc_history = np.array(w), np.array(v), np.array(loss_history), np.array(max_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(exp_dir+\"/w.npy\", w)\n",
    "np.save(exp_dir+\"/v.npy\", v)\n",
    "np.save(exp_dir+\"/loss_history.npy\", loss_history)\n",
    "np.save(exp_dir+\"/max_acc_history.npy\", max_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x104335a10>]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGHCAYAAABxmBIgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npeZkxczMzErNyYqZmZmV2t+XJ61kfBwjvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b21b510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Expected Loss of the Learner - Binary Classification\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.plot(range(len(loss_history)), loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x125f52790>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGHCAYAAACnPchFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125f09390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Maximum Accuracy of Hypothesis - Binary Classication\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim((.75,.79))\n",
    "plt.xlabel(\"Rounds\")\n",
    "plt.plot(range(len(max_acc_history)), max_acc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selectImage(i, evalX, v):\n",
    "    images = []\n",
    "    originalImage = evalX[i].reshape(28,28)\n",
    "    images.append(originalImage)\n",
    "    for j in xrange(len(v)):\n",
    "        images.append(v[j][i].reshape(28,28) + originalImage)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = selectImage(0, evalX, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =20\n",
    "plt.imshow(evalX[0].reshape(28,28) + v[i][0].reshape(28,28))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
